{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"b4e69e1e58f845d399236a7b7fac0c1b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4,"execution_start":1670504838978,"source_hash":"aa2a064f","tags":[]},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from enum import Enum\n","import re\n","import random\n","import wandb\n","from tqdm import tqdm\n","import helper\n","import time\n","import scan_dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"d3e98de7febf436e8fa2c702468ca3ec","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":22761,"execution_start":1670427563731,"source_hash":"afeeeb3e","tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristian2903\u001b[0m (\u001b[33matnlp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.13.6 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.13.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/Users/christianjensen/Documents/ATNLP/wandb/run-20221209_134651-2q3r0d3v</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/atnlp/test-project/runs/2q3r0d3v\" target=\"_blank\">whole-dragon-3</a></strong> to <a href=\"https://wandb.ai/atnlp/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/atnlp/test-project/runs/2q3r0d3v?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x15cd4aca0>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Replace test-project by experiment\n","wandb.init(project=\"test-project\", entity=\"atnlp\")"]},{"cell_type":"markdown","metadata":{"cell_id":"32132a2df9284530897a1a10bba84f3d","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Dataloading"]},{"cell_type":"code","execution_count":3,"metadata":{"cell_id":"86dae37bd1814db895e26dd9b7873862","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":225,"execution_start":1670503342851,"source_hash":"5cbe3f70","tags":[]},"outputs":[],"source":["# !git clone https://github.com/brendenlake/SCAN"]},{"cell_type":"code","execution_count":4,"metadata":{"cell_id":"cc2d3df152fb44318386c00221a1fcb3","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":3,"execution_start":1670503343101,"source_hash":"3c8963ba","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU not available, CPU used\n"]}],"source":["# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n","is_cuda = torch.cuda.is_available()\n","\n","# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n","if is_cuda:\n","    device = torch.device(\"cuda\")\n","    print(\"GPU is available\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU not available, CPU used\")"]},{"cell_type":"code","execution_count":5,"metadata":{"cell_id":"365f2c2cd963413c8db18fcdb8d6d4e4","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":221,"execution_start":1670503343105,"source_hash":"e08742bc","tags":[]},"outputs":[],"source":["input_lang = scan_dataset.Lang()\n","output_lang = scan_dataset.Lang()\n","\n","train_dataset = scan_dataset.ScanDataset(\n","    split=scan_dataset.ScanSplit.SIMPLE_SPLIT,\n","    input_lang=input_lang,\n","    output_lang=output_lang,\n","    train=True\n",")\n","\n","test_dataset = scan_dataset.ScanDataset(\n","    split=scan_dataset.ScanSplit.SIMPLE_SPLIT,\n","    input_lang=input_lang,\n","    output_lang=output_lang,\n","    train=False\n",")\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n","\n","MAX_LENGTH = max(train_dataset.input_lang.max_length, train_dataset.output_lang.max_length)"]},{"cell_type":"markdown","metadata":{"cell_id":"281e4ae4d4b7471f91e10f4b9f2ec8f4","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Model"]},{"cell_type":"code","execution_count":6,"metadata":{"cell_id":"33011efe5de34b2b8a19c8befaa2d835","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":0,"execution_start":1670503347116,"source_hash":"495cf6ab","tags":[]},"outputs":[],"source":["def init_hidden(rnn_type, n_layers, hidden_size):\n","    if rnn_type == 'LSTM':\n","        return (\n","            torch.zeros(n_layers, 1, hidden_size, device=device),\n","            torch.zeros(n_layers, 1, hidden_size, device=device)\n","        )\n","    return torch.zeros(n_layers, 1, hidden_size, device=device)"]},{"cell_type":"code","execution_count":82,"metadata":{"cell_id":"86f81ce0fc0546beb8d8d291df73eb0b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2,"execution_start":1670503347765,"source_hash":"9d0372b3","tags":[]},"outputs":[],"source":["class EncoderCell(nn.Module):\n","    def __init__(self, input_size, hidden_size, n_layers=1, rnn_type='RNN', dropout_p=0.1):\n","        super(EncoderCell, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.n_layers = n_layers\n","        self.RNN_type = rnn_type\n","\n","        self.embedding = nn.Embedding(input_size, self.hidden_size)\n","\n","        self.dropout = nn.Dropout(dropout_p)\n","\n","        self.rnn = nn.__dict__[self.RNN_type](\n","            input_size=self.hidden_size,\n","            hidden_size=self.hidden_size,\n","            num_layers=self.n_layers,\n","            dropout=dropout_p\n","        )\n","\n","    def forward(self, encoder_input, hidden):\n","        output = self.embedding(encoder_input).view(1, 1, -1)\n","        output = self.dropout(output)\n","        output, hidden = self.rnn(output, hidden)\n","        return output, hidden\n","\n","    def init_hidden(self):\n","        return init_hidden(self.RNN_type, self.n_layers, self.hidden_size)"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[],"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, device, n_layers=1, rnn_type='RNN', dropout_p=0.1):\n","        super(EncoderRNN, self).__init__()\n","        self.device = device\n","        self.encoder_cell = EncoderCell(input_size, hidden_size, n_layers, rnn_type, dropout_p)\n","\n","    def forward(self, input):\n","        encoder_hidden = self.encoder_cell.init_hidden()\n","\n","        input_length = input.size(0)\n","\n","        encoder_hidden_all = torch.zeros(input_length, self.encoder_cell.hidden_size, device=self.device) # Stores all hidden states\n","\n","        for ei in range(input_length):\n","            _, encoder_hidden =  self.encoder_cell(\n","                input[ei], encoder_hidden)\n","            if  self.encoder_cell.RNN_type == 'LSTM':\n","                encoder_hidden_all[ei] = encoder_hidden[0][0, 0]\n","            else:\n","                encoder_hidden_all[ei] = encoder_hidden[0, 0]\n","\n","        return encoder_hidden, encoder_hidden_all"]},{"cell_type":"code","execution_count":86,"metadata":{"cell_id":"41de8cc24db84ccb9baf075d5ce51abf","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":6,"execution_start":1670503348495,"source_hash":"14f5e73b","tags":[]},"outputs":[],"source":["class DecoderCell(nn.Module):\n","    def __init__(self, output_size, hidden_size, n_layers=1, rnn_type='RNN', dropout_p=0.1):\n","        super(DecoderCell, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.n_layers = n_layers\n","        self.output_size = output_size\n","        self.RNN_type = rnn_type\n","\n","        self.embedding = nn.Embedding(output_size, self.hidden_size)\n","\n","        self.dropout = nn.Dropout(dropout_p)\n","\n","        self.rnn = nn.__dict__[self.RNN_type](\n","            input_size=self.hidden_size,\n","            hidden_size=self.hidden_size,\n","            num_layers=self.n_layers,\n","            dropout=dropout_p\n","        )\n","\n","        self.out = nn.Linear(self.hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, decoder_input, hidden):\n","        output = self.embedding(decoder_input).view(1, 1, -1)\n","        output = self.dropout(output)\n","        output = F.relu(output)\n","        \n","        output, hidden = self.rnn(output, hidden)\n","        output = self.softmax(self.out(output[0]))\n","        return output, hidden\n","\n","    def init_hidden(self):\n","        return init_hidden(self.RNN_type, self.n_layers, self.hidden_size)"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[],"source":["class AttnDecoderCell(nn.Module):\n","    def __init__(self, output_size, hidden_size, n_layers=1, rnn_type='RNN', dropout_p=0.1):\n","        super(AttnDecoderCell, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.n_layers = n_layers\n","        self.output_size = output_size\n","        self.RNN_type = rnn_type\n","\n","        self.rnn = nn.__dict__[self.RNN_type](\n","            input_size=self.hidden_size,\n","            hidden_size=self.hidden_size*2,\n","            num_layers=self.n_layers,\n","            dropout=dropout_p\n","        )\n","        self.W = nn.Parameter(torch.randn((self.hidden_size, self.hidden_size)))\n","        self.U = nn.Parameter(torch.randn((self.hidden_size, self.hidden_size)))\n","        self.v = nn.Parameter(torch.randn((self.hidden_size, 1)))\n","\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","\n","        self.dropout = nn.Dropout(dropout_p)\n","\n","        self.out = nn.Linear(self.hidden_size*2, output_size)\n","\n","    def e(self, g, h):\n","        \"\"\"Computes the similarity between the previous decoder hidden state g and an encoder hidden state h\"\"\"\n","        # vT tanh(W g_(i-1) + U h_t)\n","        return self.v.T @ torch.tanh(self.W * g + self.U * h)\n","\n","    def alpha(self, encoder_hiddens, input_hidden, t):\n","        \"\"\"Computes the attention weight for a given encoder hidden state\"\"\"\n","        # alpha_it = exp(e(g_(i-1), h_t)) / sum(exp(e(g_(i-1), h_j)))\n","        T = len(encoder_hiddens)\n","        numerator = torch.exp(self.e(input_hidden, encoder_hiddens[t]))\n","\n","        denominator = 0\n","\n","        for j in range(T):\n","            denominator += torch.exp(self.e(input_hidden, encoder_hiddens[j]))\n","\n","        return numerator/denominator\n","\n","\n","    def forward(self, input, input_hidden, encoder_hiddens):\n","\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","\n","        # c_i = sum(alpha_it * h_t)\n","        c_i = 0\n","\n","        for t in range(len(encoder_hiddens)):\n","            alpha_it = self.alpha(encoder_hiddens, input_hidden, t)\n","            h_t = encoder_hiddens[t]\n","            c_i += alpha_it * h_t\n","\n","        hidden = torch.concat((input_hidden, c_i), dim=2) # Concatenate the context vector and the decoder hidden state\n","        \n","        output, hidden = self.rnn(embedded, hidden) \n","\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","\n","        # Seperate the concatenated hidden state into the decoder hidden state and the context vector\n","        hidden, context = torch.split(hidden, self.hidden_size, dim=2)\n","\n","        return output, hidden"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[],"source":["class DecoderRNN(nn.Module):\n","    def __init__(self, output_size, hidden_size, n_layers=1, rnn_type='RNN', dropout_p=0.1, attention=False):\n","        super(DecoderRNN, self).__init__()\n","\n","        self.attention = attention\n","        if attention:\n","            self.decoder_cell = AttnDecoderCell(output_size, hidden_size, n_layers, rnn_type, dropout_p)\n","        else:\n","            self.decoder_cell = DecoderCell(output_size, hidden_size, n_layers, rnn_type, dropout_p)\n","\n","    def forward(self, input, hidden, encoder_hiddens=None):\n","        assert encoder_hiddens if self.attention else True # If attention is used, all encoder hidden states must be provided\n","        if self.attention:\n","            output, hidden = self.decoder_cell(input, hidden, encoder_hiddens)\n","        else:\n","            output, hidden = self.decoder_cell(input, hidden)\n","            \n","        return output, hidden"]},{"cell_type":"code","execution_count":90,"metadata":{"cell_id":"d62e5697557c4fd2a20b7c8558f4f563","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2,"execution_start":1670503350433,"source_hash":"eeee3fab","tags":[]},"outputs":[],"source":["teacher_forcing_ratio = .5\n","\n","\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion,\n","          max_length=MAX_LENGTH):\n","    \n","    # Reset the gradients and loss\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    loss = 0\n","\n","    # Encode the input\n","    encoder_hidden, encoder_hidden_all = encoder(input_tensor)\n","\n","    # Prepare the initial decoder input\n","    decoder_input = torch.tensor([[scan_dataset.SOS_token]], device=device)\n","\n","    decoder_hidden = encoder_hidden\n","\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    target_length = target_tensor.size(0)\n","    for di in range(target_length):\n","        # Decode next token\n","        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_hidden_all)\n","            \n","        loss += criterion(decoder_output, target_tensor[di])\n","\n","        # If teacher forcing is used, the next input is the target\n","        # Otherwise, the next input is the output with the highest probability\n","        if use_teacher_forcing:\n","            decoder_input = target_tensor[di]\n","        else:\n","            topv, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\n","\n","        # If the decoder input is the EOS token, stop decoding\n","        if decoder_input.item() == scan_dataset.EOS_token:\n","                break\n","\n","    loss.backward()\n","\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length"]},{"cell_type":"code","execution_count":91,"metadata":{"cell_id":"163b98d7c7f14ab9bfb74d0a4ad0a5a2","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2,"execution_start":1670503353455,"source_hash":"fe5cb239","tags":[]},"outputs":[],"source":["def train_iterations(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=1e-2):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","    criterion = nn.NLLLoss()\n","\n","    for iteration in range(1, n_iters + 1):\n","        X, y = train_dataset[random.randrange(len(train_dataset))]\n","        input_tensor, target_tensor = train_dataset.convert_to_tensor(X, y)\n","\n","        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","\n","        if iteration % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            # wandb.log({\"avg_loss\": print_loss_avg})\n","            print('%s (%d %d%%) %.4f' % (helper.time_since(start, iteration / n_iters),\n","                                         iteration, iteration / n_iters * 100, print_loss_avg))\n","\n","        if iteration % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0\n","\n","    helper.show_plot(plot_losses)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def evaluate(dataset, encoder, decoder, max_length, verbose=False, batch_size=1, shuffle=False):\n","    encoder.eval()\n","    decoder.eval()\n","    \n","    accs = []\n","    \n","    with torch.no_grad():\n","        for input_tensor, target_tensor in tqdm(dataset, total=len(dataset), leave=False, desc=\"Evaluating\"):\n","            input_tensor, target_tensor = dataset.convert_to_tensor(input_tensor, target_tensor)\n","            \n","            preds = []\n","\n","            encoder_hidden = encoder.init_hidden()\n","\n","            input_length = input_tensor.size(0)\n","            target_length = target_tensor.size(0)\n","\n","            encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","            for ei in range(input_length):\n","                encoder_output, encoder_hidden = encoder(\n","                    input_tensor[ei], encoder_hidden)\n","                encoder_outputs[ei] = encoder_output[0, 0]\n","\n","            decoder_input = torch.tensor([[scan_dataset.SOS_token]], device=device)\n","\n","            decoder_hidden = encoder_hidden\n","\n","            for di in range(target_length):\n","                try:\n","                    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","                except TypeError:\n","                    decoder_output, decoder_hidden, decoder_attention = decoder(\n","                        decoder_input, decoder_hidden, encoder_outputs)\n","\n","                topv, topi = decoder_output.topk(1)\n","                decoder_input = topi.squeeze().detach()  # detach from history as input\n","\n","                preds.append(decoder_input.item())\n","\n","                if decoder_input.item() == scan_dataset.EOS_token:\n","                    break\n","\n","            preds = np.array(preds)\n","            gts = target_tensor.detach().cpu().numpy().squeeze()\n","\n","            if len(preds) == len(gts):\n","                accs.append(np.all(preds == gts))\n","            else:\n","                accs.append(0)\n","            \n","    if verbose:\n","        print(\"Accuracy\", np.mean(accs))\n","        \n","    encoder.train()\n","    decoder.train()\n","\n","    return np.mean(accs)"]},{"cell_type":"code","execution_count":92,"metadata":{"cell_id":"a49864cef1ec4e8d9dc3eef04e232090","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":592,"execution_start":1670428498511,"source_hash":"a430f441","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["0m 8s (- 1m 19s) (1000 10%) 3.3013\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/ipykernel_46094/2919302880.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# decoder1 = AttnDecoderRNN(train_dataset.output_lang.n_words, config['HIDDEN_SIZE'], config['N_LAYERS'], config['RNN_TYPE'], config['RNN_TYPE']).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/ipykernel_46094/3964706250.py\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/ipykernel_46094/3905695955.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Decode next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/ipykernel_46094/3577546676.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, encoder_hiddens)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/ipykernel_46094/290307271.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, decoder_input, hidden)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"log_softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["hidden_size = 256\n","\n","config = {\n","    'HIDDEN_SIZE': 256, # 25, 50, 100, 200, or 400\n","    'RNN_TYPE': 'RNN', # RNN, GRU or LSTM\n","    'N_LAYERS': 2, # 1 or 2\n","    'DROPOUT': 0, # 0, 0.1 or 0.5\n","}\n","\n","wandb.config = config\n","\n","encoder1 = EncoderRNN(train_dataset.input_lang.n_words, config['HIDDEN_SIZE'], device, config['N_LAYERS'], config['RNN_TYPE'], config['DROPOUT']).to(device)\n","decoder1 = DecoderRNN(train_dataset.output_lang.n_words, config['HIDDEN_SIZE'], config['N_LAYERS'], config['RNN_TYPE'], config['DROPOUT']).to(device)\n","# decoder1 = AttnDecoderRNN(train_dataset.output_lang.n_words, config['HIDDEN_SIZE'], config['N_LAYERS'], config['RNN_TYPE'], config['RNN_TYPE']).to(device)\n","\n","train_iterations(encoder1, decoder1, 10000, print_every=1000)"]},{"cell_type":"markdown","metadata":{"cell_id":"173c017af69b464c9f2ecbdfd1774a22","deepnote_cell_type":"text-cell-h3","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["### Experiment 1"]},{"cell_type":"markdown","metadata":{"cell_id":"55ce5211cbff4c5e8e900aded7380f89","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["The top-performing architecture was a LSTM with no attention, 2\n","layers of 200 hidden units, and no dropout. The best-overall\n","network achieved 99.7% correct."]},{"cell_type":"markdown","metadata":{"cell_id":"e5b250c9-18cf-47cd-9913-1791cf3a6eb3","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["SCAN tasks were randomly split into a training set (80%) and a test set (20%)."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"8b055f021e124ff7a02904bfcddda40b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"b623e53d","tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"7b78a617eb554d6b9f9c3d5f9bf38cd8","deepnote_cell_type":"text-cell-h3","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["### Experiment 2"]},{"cell_type":"markdown","metadata":{"cell_id":"6810bb7d3b0c49eba78f38d3a8753986","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["The best result (20.8% on average, again over 5 runs) is achieved\n","by a GRU with attention, one 50-dimensional hidden layer,\n","and dropout 0.5"]},{"cell_type":"code","execution_count":13,"metadata":{"cell_id":"ee5ff92d4ca94a79aa878f58f62a34c7","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":6333,"execution_start":1670504921436,"source_hash":"4493d43e","tags":[]},"outputs":[{"data":{"text/html":["Finishing last run (ID:2q3r0d3v) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af22ae7ea0284329b2404b301cfa0c24","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Synced <strong style=\"color:#cdcd00\">whole-dragon-3</strong>: <a href=\"https://wandb.ai/atnlp/test-project/runs/2q3r0d3v\" target=\"_blank\">https://wandb.ai/atnlp/test-project/runs/2q3r0d3v</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20221209_134651-2q3r0d3v/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:2q3r0d3v). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"601c0de38b1b4b029503d61fbd53b3fa","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.03348856767018636, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["wandb version 0.13.6 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.13.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/Users/christianjensen/Documents/ATNLP/wandb/run-20221209_134704-15z4thmq</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/atnlp/experiment-2/runs/15z4thmq\" target=\"_blank\">ruby-galaxy-7</a></strong> to <a href=\"https://wandb.ai/atnlp/experiment-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/atnlp/experiment-2/runs/15z4thmq?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x15d9984f0>"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init(project=\"experiment-2\", entity=\"atnlp\")"]},{"cell_type":"code","execution_count":14,"metadata":{"cell_id":"aac03ce487824b95b8858ca8957bfac3","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1,"execution_start":1670504927771,"source_hash":"49b6a13c","tags":[]},"outputs":[{"ename":"NameError","evalue":"name 'Lang' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/ipykernel_46094/3164604928.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_lang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput_lang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Lang' is not defined"]}],"source":["input_lang = Lang()\n","output_lang = Lang()"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"488fdc94c8854fe7b3aefd2eb3b033c8","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":168,"execution_start":1670504927773,"source_hash":"6bb56092","tags":[]},"outputs":[],"source":["train_dataset = ScanDataset(\n","    split=ScanSplit.LENGTH_SPLIT,\n","    input_lang=input_lang,\n","    output_lang=output_lang,\n","    train=True\n",")\n","\n","test_dataset = ScanDataset(\n","    split=ScanSplit.LENGTH_SPLIT,\n","    input_lang=input_lang,\n","    output_lang=output_lang,\n","    train=False\n",")\n","\n","assert (len(train_dataset) == 16990)\n","assert (len(test_dataset) == 3920)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"3143f6fa0b99463fba724730c39666a7","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":3,"execution_start":1670504930131,"source_hash":"cd3df8c1","tags":[]},"outputs":[],"source":["experiment_2_config = dict(HIDDEN_SIZE=50, N_LAYERS=1, DROPOUT=.5, RNN_TYPE='GRU')\n","overall_best_config = dict(HIDDEN_SIZE=200, N_LAYERS=2, DROPOUT=.5, RNN_TYPE='LSTM')\n","\n","config = experiment_2_config"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"1c229374e5574fc79c8ac726489a6d08","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":6,"execution_start":1670504931413,"source_hash":"f8dd64c8","tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]}],"source":["encoder_exp_2 = EncoderRNN(input_lang.n_words, config=config).to(device)\n","decoder_exp_2 = DecoderRNN(output_lang.n_words, config=config).to(device)\n","attn_decoder_exp_2 = AttnDecoderRNN(output_lang.n_words, config=config).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"70fb46eddada431a9e528181fa9d602d","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":491853,"execution_start":1670504938824,"source_hash":"5b1bc7dd","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["0m 4s (- 7m 30s) (100 1%) 2.1491\n","0m 9s (- 7m 53s) (200 2%) 1.8391\n","0m 14s (- 7m 40s) (300 3%) 1.8041\n","0m 19s (- 7m 37s) (400 4%) 1.7459\n","0m 24s (- 7m 37s) (500 5%) 1.7441\n","0m 28s (- 7m 27s) (600 6%) 1.7132\n","0m 33s (- 7m 20s) (700 7%) 1.7615\n","0m 38s (- 7m 19s) (800 8%) 1.6810\n","0m 43s (- 7m 18s) (900 9%) 1.6580\n","0m 48s (- 7m 13s) (1000 10%) 1.6702\n","0m 52s (- 7m 6s) (1100 11%) 1.6138\n","0m 57s (- 7m 0s) (1200 12%) 1.4693\n","1m 2s (- 6m 56s) (1300 13%) 1.5826\n","1m 7s (- 6m 53s) (1400 14%) 1.5038\n","1m 12s (- 6m 52s) (1500 15%) 1.5233\n","1m 18s (- 6m 49s) (1600 16%) 1.3632\n","1m 23s (- 6m 46s) (1700 17%) 1.4715\n","1m 28s (- 6m 43s) (1800 18%) 1.4320\n","1m 34s (- 6m 40s) (1900 19%) 1.4505\n","1m 39s (- 6m 36s) (2000 20%) 1.4093\n","1m 44s (- 6m 32s) (2100 21%) 1.3209\n","1m 49s (- 6m 26s) (2200 22%) 1.3297\n","1m 54s (- 6m 21s) (2300 23%) 1.3695\n","1m 58s (- 6m 15s) (2400 24%) 1.3888\n","2m 3s (- 6m 10s) (2500 25%) 1.2416\n","2m 8s (- 6m 7s) (2600 26%) 1.3154\n","2m 14s (- 6m 3s) (2700 27%) 1.3073\n","2m 20s (- 6m 0s) (2800 28%) 1.2706\n","2m 25s (- 5m 55s) (2900 28%) 1.2736\n","2m 29s (- 5m 49s) (3000 30%) 1.1818\n","2m 34s (- 5m 44s) (3100 31%) 1.2034\n","2m 39s (- 5m 39s) (3200 32%) 1.2313\n","2m 44s (- 5m 33s) (3300 33%) 1.1804\n","2m 49s (- 5m 28s) (3400 34%) 1.1946\n","2m 54s (- 5m 23s) (3500 35%) 1.2571\n","2m 58s (- 5m 17s) (3600 36%) 1.1272\n","3m 3s (- 5m 11s) (3700 37%) 1.2691\n","3m 7s (- 5m 6s) (3800 38%) 1.1276\n","3m 12s (- 5m 0s) (3900 39%) 1.0795\n","3m 17s (- 4m 55s) (4000 40%) 1.1970\n","3m 21s (- 4m 50s) (4100 41%) 1.0799\n","3m 26s (- 4m 45s) (4200 42%) 1.1466\n","3m 31s (- 4m 40s) (4300 43%) 1.1299\n","3m 36s (- 4m 35s) (4400 44%) 1.1110\n","3m 41s (- 4m 30s) (4500 45%) 1.0664\n","3m 45s (- 4m 25s) (4600 46%) 1.1488\n","3m 50s (- 4m 20s) (4700 47%) 1.0704\n","3m 55s (- 4m 15s) (4800 48%) 1.0589\n","4m 1s (- 4m 11s) (4900 49%) 1.1836\n","4m 6s (- 4m 6s) (5000 50%) 1.0840\n","4m 11s (- 4m 1s) (5100 51%) 1.0518\n","4m 16s (- 3m 56s) (5200 52%) 1.0239\n","4m 21s (- 3m 51s) (5300 53%) 1.1148\n","4m 25s (- 3m 46s) (5400 54%) 1.0871\n","4m 30s (- 3m 41s) (5500 55%) 1.0094\n","4m 35s (- 3m 36s) (5600 56%) 1.0700\n","4m 40s (- 3m 31s) (5700 56%) 0.9588\n","4m 44s (- 3m 26s) (5800 57%) 0.9640\n","4m 49s (- 3m 21s) (5900 59%) 0.9953\n","4m 54s (- 3m 16s) (6000 60%) 0.9529\n","4m 58s (- 3m 11s) (6100 61%) 1.0720\n","5m 3s (- 3m 6s) (6200 62%) 1.0522\n","5m 8s (- 3m 1s) (6300 63%) 0.9502\n","5m 13s (- 2m 56s) (6400 64%) 0.9330\n","5m 18s (- 2m 51s) (6500 65%) 1.0032\n","5m 22s (- 2m 46s) (6600 66%) 0.8894\n","5m 27s (- 2m 41s) (6700 67%) 0.9124\n","5m 32s (- 2m 36s) (6800 68%) 0.9259\n","5m 37s (- 2m 31s) (6900 69%) 0.9369\n","5m 42s (- 2m 26s) (7000 70%) 0.9348\n","5m 46s (- 2m 21s) (7100 71%) 0.9371\n","5m 51s (- 2m 16s) (7200 72%) 0.8928\n","5m 56s (- 2m 11s) (7300 73%) 0.8600\n","6m 1s (- 2m 7s) (7400 74%) 0.9569\n","6m 7s (- 2m 2s) (7500 75%) 0.9180\n","6m 11s (- 1m 57s) (7600 76%) 0.8699\n","6m 16s (- 1m 52s) (7700 77%) 0.8710\n","6m 20s (- 1m 47s) (7800 78%) 0.9819\n","6m 25s (- 1m 42s) (7900 79%) 0.9201\n","6m 30s (- 1m 37s) (8000 80%) 0.7852\n","6m 35s (- 1m 32s) (8100 81%) 0.8309\n","6m 40s (- 1m 27s) (8200 82%) 0.8153\n","6m 44s (- 1m 22s) (8300 83%) 0.8456\n","6m 49s (- 1m 18s) (8400 84%) 0.8527\n","6m 54s (- 1m 13s) (8500 85%) 0.8404\n","6m 58s (- 1m 8s) (8600 86%) 0.8217\n","7m 3s (- 1m 3s) (8700 87%) 0.8000\n","7m 8s (- 0m 58s) (8800 88%) 0.7513\n","7m 13s (- 0m 53s) (8900 89%) 0.7096\n","7m 18s (- 0m 48s) (9000 90%) 0.7082\n","7m 23s (- 0m 43s) (9100 91%) 0.7636\n","7m 29s (- 0m 39s) (9200 92%) 0.7665\n","7m 35s (- 0m 34s) (9300 93%) 0.7916\n","7m 41s (- 0m 29s) (9400 94%) 0.7543\n","7m 46s (- 0m 24s) (9500 95%) 0.6984\n","7m 51s (- 0m 19s) (9600 96%) 0.6854\n","7m 56s (- 0m 14s) (9700 97%) 0.7542\n","8m 1s (- 0m 9s) (9800 98%) 0.7373\n","8m 6s (- 0m 4s) (9900 99%) 0.7100\n","8m 11s (- 0m 0s) (10000 100%) 0.7140\n"]}],"source":["train_iterations(encoder_exp_2, attn_decoder_exp_2, 10000, print_every=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"825c7142088549c5b524881463b8eb34","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":13478,"execution_start":1670505430680,"source_hash":"e13b4d80","tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":[]},{"data":{"text/plain":["0.0"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["evaluate(test_dataset, encoder_exp_2, attn_decoder_exp_2)"]},{"cell_type":"markdown","metadata":{"cell_id":"58d77281f8ff46aa8124835bd73212a9","deepnote_cell_type":"text-cell-h3","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["### Experiment 3"]},{"cell_type":"markdown","metadata":{"cell_id":"2db6686e0951479c9500c5a1d1fb7d89","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["The best performance is achieved by\n","a GRU network with attention, one layer with 100 hidden\n","units, and dropout of 0.1 (90.3% accuracy). "]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"2bfbc1a109ab460a81c8e56a56db610d","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"b623e53d","tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown","tags":[]},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ec00d141-8917-4313-a10a-78395d2ec852' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"aa078de21384434e9243e98f7929ffe5","deepnote_persisted_session":{"createdAt":"2022-12-08T13:47:47.198Z"},"kernelspec":{"display_name":"Python 3.9.15 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"},"orig_nbformat":2,"vscode":{"interpreter":{"hash":"a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"}}},"nbformat":4,"nbformat_minor":0}
