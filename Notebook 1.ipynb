{"cells":[{"cell_type":"code","execution_count":97,"metadata":{"cell_id":"b4e69e1e58f845d399236a7b7fac0c1b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4,"execution_start":1670504838978,"source_hash":"aa2a064f","tags":[]},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from enum import Enum\n","import re\n","import random\n","import wandb\n","from tqdm import tqdm\n","import helper\n","import time\n","import scan_dataset\n","import models"]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"d3e98de7febf436e8fa2c702468ca3ec","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":22761,"execution_start":1670427563731,"source_hash":"afeeeb3e","tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristian2903\u001b[0m (\u001b[33matnlp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.13.6 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.13.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/Users/christianjensen/Documents/ATNLP/wandb/run-20221209_134651-2q3r0d3v</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/atnlp/test-project/runs/2q3r0d3v\" target=\"_blank\">whole-dragon-3</a></strong> to <a href=\"https://wandb.ai/atnlp/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/atnlp/test-project/runs/2q3r0d3v?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x15cd4aca0>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Replace test-project by experiment\n","wandb.init(project=\"test-project\", entity=\"atnlp\")"]},{"cell_type":"code","execution_count":3,"metadata":{"cell_id":"86dae37bd1814db895e26dd9b7873862","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":225,"execution_start":1670503342851,"source_hash":"5cbe3f70","tags":[]},"outputs":[],"source":["# !git clone https://github.com/brendenlake/SCAN"]},{"cell_type":"code","execution_count":4,"metadata":{"cell_id":"cc2d3df152fb44318386c00221a1fcb3","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":3,"execution_start":1670503343101,"source_hash":"3c8963ba","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU not available, CPU used\n"]}],"source":["# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n","is_cuda = torch.cuda.is_available()\n","\n","# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n","if is_cuda:\n","    device = torch.device(\"cuda\")\n","    print(\"GPU is available\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU not available, CPU used\")"]},{"cell_type":"code","execution_count":5,"metadata":{"cell_id":"365f2c2cd963413c8db18fcdb8d6d4e4","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":221,"execution_start":1670503343105,"source_hash":"e08742bc","tags":[]},"outputs":[],"source":["input_lang = scan_dataset.Lang()\n","output_lang = scan_dataset.Lang()\n","\n","train_dataset = scan_dataset.ScanDataset(\n","    split=scan_dataset.ScanSplit.SIMPLE_SPLIT,\n","    input_lang=input_lang,\n","    output_lang=output_lang,\n","    train=True\n",")\n","\n","test_dataset = scan_dataset.ScanDataset(\n","    split=scan_dataset.ScanSplit.SIMPLE_SPLIT,\n","    input_lang=input_lang,\n","    output_lang=output_lang,\n","    train=False\n",")\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n","\n","MAX_LENGTH = max(train_dataset.input_lang.max_length, train_dataset.output_lang.max_length)"]},{"cell_type":"code","execution_count":106,"metadata":{"cell_id":"d62e5697557c4fd2a20b7c8558f4f563","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2,"execution_start":1670503350433,"source_hash":"eeee3fab","tags":[]},"outputs":[],"source":["teacher_forcing_ratio = .5\n","\n","def train_iteration(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n","    \"\"\"A single training iteration.\"\"\"\n","    # Reset the gradients and loss\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    loss = 0\n","\n","    # Encode the input\n","    encoder_hidden, encoder_hidden_all = encoder(input_tensor)\n","\n","    # Prepare the initial decoder input\n","    decoder_input = torch.tensor([[scan_dataset.SOS_token]], device=device)\n","\n","    decoder_hidden = encoder_hidden\n","\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    target_length = target_tensor.size(0)\n","    for di in range(target_length):\n","        # Decode next token\n","        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_hidden_all)\n","            \n","        loss += criterion(decoder_output, target_tensor[di])\n","\n","        # If teacher forcing is used, the next input is the target\n","        # Otherwise, the next input is the output with the highest probability\n","        if use_teacher_forcing:\n","            decoder_input = target_tensor[di]\n","        else:\n","            topv, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\n","\n","        # If the decoder input is the EOS token, stop decoding\n","        if decoder_input.item() == scan_dataset.EOS_token:\n","                break\n","\n","    loss.backward()\n","\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length"]},{"cell_type":"code","execution_count":107,"metadata":{"cell_id":"163b98d7c7f14ab9bfb74d0a4ad0a5a2","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2,"execution_start":1670503353455,"source_hash":"fe5cb239","tags":[]},"outputs":[],"source":["def train(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=1e-2):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","    criterion = nn.NLLLoss()\n","\n","    for iteration in range(1, n_iters + 1):\n","        X, y = train_dataset[random.randrange(len(train_dataset))]\n","        input_tensor, target_tensor = train_dataset.convert_to_tensor(X, y)\n","\n","        loss = train_iteration(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","\n","        if iteration % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            # wandb.log({\"avg_loss\": print_loss_avg})\n","            print('%s (%d %d%%) %.4f' % (helper.time_since(start, iteration / n_iters),\n","                                         iteration, iteration / n_iters * 100, print_loss_avg))\n","\n","        if iteration % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0\n","\n","    helper.show_plot(plot_losses)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def evaluate(dataset, encoder, decoder, max_length, verbose=False, batch_size=1, shuffle=False):\n","    encoder.eval()\n","    decoder.eval()\n","    \n","    accs = []\n","    \n","    with torch.no_grad():\n","        for input_tensor, target_tensor in tqdm(dataset, total=len(dataset), leave=False, desc=\"Evaluating\"):\n","            input_tensor, target_tensor = dataset.convert_to_tensor(input_tensor, target_tensor)\n","            \n","            preds = []\n","\n","            encoder_hidden = encoder.init_hidden()\n","\n","            input_length = input_tensor.size(0)\n","            target_length = target_tensor.size(0)\n","\n","            encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","            for ei in range(input_length):\n","                encoder_output, encoder_hidden = encoder(\n","                    input_tensor[ei], encoder_hidden)\n","                encoder_outputs[ei] = encoder_output[0, 0]\n","\n","            decoder_input = torch.tensor([[scan_dataset.SOS_token]], device=device)\n","\n","            decoder_hidden = encoder_hidden\n","\n","            for di in range(target_length):\n","                try:\n","                    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","                except TypeError:\n","                    decoder_output, decoder_hidden, decoder_attention = decoder(\n","                        decoder_input, decoder_hidden, encoder_outputs)\n","\n","                topv, topi = decoder_output.topk(1)\n","                decoder_input = topi.squeeze().detach()  # detach from history as input\n","\n","                preds.append(decoder_input.item())\n","\n","                if decoder_input.item() == scan_dataset.EOS_token:\n","                    break\n","\n","            preds = np.array(preds)\n","            gts = target_tensor.detach().cpu().numpy().squeeze()\n","\n","            if len(preds) == len(gts):\n","                accs.append(np.all(preds == gts))\n","            else:\n","                accs.append(0)\n","            \n","    if verbose:\n","        print(\"Accuracy\", np.mean(accs))\n","        \n","    encoder.train()\n","    decoder.train()\n","\n","    return np.mean(accs)"]},{"cell_type":"code","execution_count":109,"metadata":{"cell_id":"a49864cef1ec4e8d9dc3eef04e232090","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":592,"execution_start":1670428498511,"source_hash":"a430f441","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["0m 0s (- 2m 3s) (10 0%) 3.3669\n","0m 0s (- 1m 49s) (20 0%) 7.8019\n","0m 0s (- 1m 40s) (30 0%) 5.7184\n","0m 0s (- 1m 38s) (40 0%) 4.1964\n","0m 0s (- 1m 38s) (50 0%) 3.0679\n","0m 0s (- 1m 36s) (60 0%) 2.7543\n","0m 0s (- 1m 36s) (70 0%) 2.7801\n","0m 0s (- 1m 35s) (80 0%) 2.3384\n","0m 0s (- 1m 36s) (90 0%) 3.0742\n","0m 0s (- 1m 35s) (100 1%) 2.8176\n","0m 1s (- 1m 34s) (110 1%) 2.6878\n","0m 1s (- 1m 34s) (120 1%) 3.1294\n","0m 1s (- 1m 34s) (130 1%) 3.4889\n","0m 1s (- 1m 34s) (140 1%) 3.0169\n","0m 1s (- 1m 34s) (150 1%) 2.8700\n","0m 1s (- 1m 35s) (160 1%) 3.6825\n","0m 1s (- 1m 37s) (170 1%) 2.9920\n","0m 1s (- 1m 40s) (180 1%) 2.9205\n","0m 1s (- 1m 39s) (190 1%) 3.4127\n","0m 2s (- 1m 39s) (200 2%) 3.7497\n","0m 2s (- 1m 38s) (210 2%) 2.9122\n","0m 2s (- 1m 38s) (220 2%) 3.0041\n","0m 2s (- 1m 37s) (230 2%) 2.8855\n","0m 2s (- 1m 37s) (240 2%) 3.7606\n","0m 2s (- 1m 38s) (250 2%) 2.6033\n","0m 2s (- 1m 37s) (260 2%) 2.6463\n","0m 2s (- 1m 37s) (270 2%) 2.9833\n","0m 2s (- 1m 37s) (280 2%) 2.9599\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/ipykernel_46094/1557901674.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# decoder1 = AttnDecoderRNN(train_dataset.output_lang.n_words, config['HIDDEN_SIZE'], config['N_LAYERS'], config['RNN_TYPE'], config['RNN_TYPE']).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/ipykernel_46094/1845679235.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/ipykernel_46094/2775009757.py\u001b[0m in \u001b[0;36mtrain_iteration\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["hidden_size = 256\n","\n","config = {\n","    'HIDDEN_SIZE': 256, # 25, 50, 100, 200, or 400\n","    'RNN_TYPE': 'RNN', # RNN, GRU or LSTM\n","    'N_LAYERS': 2, # 1 or 2\n","    'DROPOUT': 0, # 0, 0.1 or 0.5\n","}\n","\n","wandb.config = config\n","\n","encoder1 = models.EncoderRNN(train_dataset.input_lang.n_words, config['HIDDEN_SIZE'], device, config['N_LAYERS'], config['RNN_TYPE'], config['DROPOUT']).to(device)\n","decoder1 = models.DecoderRNN(train_dataset.output_lang.n_words, config['HIDDEN_SIZE'], config['N_LAYERS'], config['RNN_TYPE'], config['DROPOUT']).to(device)\n","# decoder1 = AttnDecoderRNN(train_dataset.output_lang.n_words, config['HIDDEN_SIZE'], config['N_LAYERS'], config['RNN_TYPE'], config['RNN_TYPE']).to(device)\n","\n","train(encoder1, decoder1, 10000, print_every=10)"]},{"cell_type":"markdown","metadata":{"cell_id":"173c017af69b464c9f2ecbdfd1774a22","deepnote_cell_type":"text-cell-h3","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["### Experiment 1"]},{"cell_type":"markdown","metadata":{"cell_id":"55ce5211cbff4c5e8e900aded7380f89","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["The top-performing architecture was a LSTM with no attention, 2\n","layers of 200 hidden units, and no dropout. The best-overall\n","network achieved 99.7% correct."]},{"cell_type":"markdown","metadata":{"cell_id":"e5b250c9-18cf-47cd-9913-1791cf3a6eb3","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["SCAN tasks were randomly split into a training set (80%) and a test set (20%)."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"8b055f021e124ff7a02904bfcddda40b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"b623e53d","tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"7b78a617eb554d6b9f9c3d5f9bf38cd8","deepnote_cell_type":"text-cell-h3","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["### Experiment 2"]},{"cell_type":"markdown","metadata":{"cell_id":"6810bb7d3b0c49eba78f38d3a8753986","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["The best result (20.8% on average, again over 5 runs) is achieved\n","by a GRU with attention, one 50-dimensional hidden layer,\n","and dropout 0.5"]},{"cell_type":"code","execution_count":13,"metadata":{"cell_id":"ee5ff92d4ca94a79aa878f58f62a34c7","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":6333,"execution_start":1670504921436,"source_hash":"4493d43e","tags":[]},"outputs":[{"data":{"text/html":["Finishing last run (ID:2q3r0d3v) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af22ae7ea0284329b2404b301cfa0c24","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Synced <strong style=\"color:#cdcd00\">whole-dragon-3</strong>: <a href=\"https://wandb.ai/atnlp/test-project/runs/2q3r0d3v\" target=\"_blank\">https://wandb.ai/atnlp/test-project/runs/2q3r0d3v</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20221209_134651-2q3r0d3v/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:2q3r0d3v). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"601c0de38b1b4b029503d61fbd53b3fa","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.03348856767018636, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["wandb version 0.13.6 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.13.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/Users/christianjensen/Documents/ATNLP/wandb/run-20221209_134704-15z4thmq</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/atnlp/experiment-2/runs/15z4thmq\" target=\"_blank\">ruby-galaxy-7</a></strong> to <a href=\"https://wandb.ai/atnlp/experiment-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/atnlp/experiment-2/runs/15z4thmq?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x15d9984f0>"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init(project=\"experiment-2\", entity=\"atnlp\")"]},{"cell_type":"code","execution_count":14,"metadata":{"cell_id":"aac03ce487824b95b8858ca8957bfac3","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1,"execution_start":1670504927771,"source_hash":"49b6a13c","tags":[]},"outputs":[{"ename":"NameError","evalue":"name 'Lang' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/ipykernel_46094/3164604928.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_lang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput_lang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Lang' is not defined"]}],"source":["input_lang = Lang()\n","output_lang = Lang()"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"488fdc94c8854fe7b3aefd2eb3b033c8","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":168,"execution_start":1670504927773,"source_hash":"6bb56092","tags":[]},"outputs":[],"source":["train_dataset = ScanDataset(\n","    split=ScanSplit.LENGTH_SPLIT,\n","    input_lang=input_lang,\n","    output_lang=output_lang,\n","    train=True\n",")\n","\n","test_dataset = ScanDataset(\n","    split=ScanSplit.LENGTH_SPLIT,\n","    input_lang=input_lang,\n","    output_lang=output_lang,\n","    train=False\n",")\n","\n","assert (len(train_dataset) == 16990)\n","assert (len(test_dataset) == 3920)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"3143f6fa0b99463fba724730c39666a7","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":3,"execution_start":1670504930131,"source_hash":"cd3df8c1","tags":[]},"outputs":[],"source":["experiment_2_config = dict(HIDDEN_SIZE=50, N_LAYERS=1, DROPOUT=.5, RNN_TYPE='GRU')\n","overall_best_config = dict(HIDDEN_SIZE=200, N_LAYERS=2, DROPOUT=.5, RNN_TYPE='LSTM')\n","\n","config = experiment_2_config"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"1c229374e5574fc79c8ac726489a6d08","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":6,"execution_start":1670504931413,"source_hash":"f8dd64c8","tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]}],"source":["encoder_exp_2 = EncoderRNN(input_lang.n_words, config=config).to(device)\n","decoder_exp_2 = DecoderRNN(output_lang.n_words, config=config).to(device)\n","attn_decoder_exp_2 = AttnDecoderRNN(output_lang.n_words, config=config).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"70fb46eddada431a9e528181fa9d602d","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":491853,"execution_start":1670504938824,"source_hash":"5b1bc7dd","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["0m 4s (- 7m 30s) (100 1%) 2.1491\n","0m 9s (- 7m 53s) (200 2%) 1.8391\n","0m 14s (- 7m 40s) (300 3%) 1.8041\n","0m 19s (- 7m 37s) (400 4%) 1.7459\n","0m 24s (- 7m 37s) (500 5%) 1.7441\n","0m 28s (- 7m 27s) (600 6%) 1.7132\n","0m 33s (- 7m 20s) (700 7%) 1.7615\n","0m 38s (- 7m 19s) (800 8%) 1.6810\n","0m 43s (- 7m 18s) (900 9%) 1.6580\n","0m 48s (- 7m 13s) (1000 10%) 1.6702\n","0m 52s (- 7m 6s) (1100 11%) 1.6138\n","0m 57s (- 7m 0s) (1200 12%) 1.4693\n","1m 2s (- 6m 56s) (1300 13%) 1.5826\n","1m 7s (- 6m 53s) (1400 14%) 1.5038\n","1m 12s (- 6m 52s) (1500 15%) 1.5233\n","1m 18s (- 6m 49s) (1600 16%) 1.3632\n","1m 23s (- 6m 46s) (1700 17%) 1.4715\n","1m 28s (- 6m 43s) (1800 18%) 1.4320\n","1m 34s (- 6m 40s) (1900 19%) 1.4505\n","1m 39s (- 6m 36s) (2000 20%) 1.4093\n","1m 44s (- 6m 32s) (2100 21%) 1.3209\n","1m 49s (- 6m 26s) (2200 22%) 1.3297\n","1m 54s (- 6m 21s) (2300 23%) 1.3695\n","1m 58s (- 6m 15s) (2400 24%) 1.3888\n","2m 3s (- 6m 10s) (2500 25%) 1.2416\n","2m 8s (- 6m 7s) (2600 26%) 1.3154\n","2m 14s (- 6m 3s) (2700 27%) 1.3073\n","2m 20s (- 6m 0s) (2800 28%) 1.2706\n","2m 25s (- 5m 55s) (2900 28%) 1.2736\n","2m 29s (- 5m 49s) (3000 30%) 1.1818\n","2m 34s (- 5m 44s) (3100 31%) 1.2034\n","2m 39s (- 5m 39s) (3200 32%) 1.2313\n","2m 44s (- 5m 33s) (3300 33%) 1.1804\n","2m 49s (- 5m 28s) (3400 34%) 1.1946\n","2m 54s (- 5m 23s) (3500 35%) 1.2571\n","2m 58s (- 5m 17s) (3600 36%) 1.1272\n","3m 3s (- 5m 11s) (3700 37%) 1.2691\n","3m 7s (- 5m 6s) (3800 38%) 1.1276\n","3m 12s (- 5m 0s) (3900 39%) 1.0795\n","3m 17s (- 4m 55s) (4000 40%) 1.1970\n","3m 21s (- 4m 50s) (4100 41%) 1.0799\n","3m 26s (- 4m 45s) (4200 42%) 1.1466\n","3m 31s (- 4m 40s) (4300 43%) 1.1299\n","3m 36s (- 4m 35s) (4400 44%) 1.1110\n","3m 41s (- 4m 30s) (4500 45%) 1.0664\n","3m 45s (- 4m 25s) (4600 46%) 1.1488\n","3m 50s (- 4m 20s) (4700 47%) 1.0704\n","3m 55s (- 4m 15s) (4800 48%) 1.0589\n","4m 1s (- 4m 11s) (4900 49%) 1.1836\n","4m 6s (- 4m 6s) (5000 50%) 1.0840\n","4m 11s (- 4m 1s) (5100 51%) 1.0518\n","4m 16s (- 3m 56s) (5200 52%) 1.0239\n","4m 21s (- 3m 51s) (5300 53%) 1.1148\n","4m 25s (- 3m 46s) (5400 54%) 1.0871\n","4m 30s (- 3m 41s) (5500 55%) 1.0094\n","4m 35s (- 3m 36s) (5600 56%) 1.0700\n","4m 40s (- 3m 31s) (5700 56%) 0.9588\n","4m 44s (- 3m 26s) (5800 57%) 0.9640\n","4m 49s (- 3m 21s) (5900 59%) 0.9953\n","4m 54s (- 3m 16s) (6000 60%) 0.9529\n","4m 58s (- 3m 11s) (6100 61%) 1.0720\n","5m 3s (- 3m 6s) (6200 62%) 1.0522\n","5m 8s (- 3m 1s) (6300 63%) 0.9502\n","5m 13s (- 2m 56s) (6400 64%) 0.9330\n","5m 18s (- 2m 51s) (6500 65%) 1.0032\n","5m 22s (- 2m 46s) (6600 66%) 0.8894\n","5m 27s (- 2m 41s) (6700 67%) 0.9124\n","5m 32s (- 2m 36s) (6800 68%) 0.9259\n","5m 37s (- 2m 31s) (6900 69%) 0.9369\n","5m 42s (- 2m 26s) (7000 70%) 0.9348\n","5m 46s (- 2m 21s) (7100 71%) 0.9371\n","5m 51s (- 2m 16s) (7200 72%) 0.8928\n","5m 56s (- 2m 11s) (7300 73%) 0.8600\n","6m 1s (- 2m 7s) (7400 74%) 0.9569\n","6m 7s (- 2m 2s) (7500 75%) 0.9180\n","6m 11s (- 1m 57s) (7600 76%) 0.8699\n","6m 16s (- 1m 52s) (7700 77%) 0.8710\n","6m 20s (- 1m 47s) (7800 78%) 0.9819\n","6m 25s (- 1m 42s) (7900 79%) 0.9201\n","6m 30s (- 1m 37s) (8000 80%) 0.7852\n","6m 35s (- 1m 32s) (8100 81%) 0.8309\n","6m 40s (- 1m 27s) (8200 82%) 0.8153\n","6m 44s (- 1m 22s) (8300 83%) 0.8456\n","6m 49s (- 1m 18s) (8400 84%) 0.8527\n","6m 54s (- 1m 13s) (8500 85%) 0.8404\n","6m 58s (- 1m 8s) (8600 86%) 0.8217\n","7m 3s (- 1m 3s) (8700 87%) 0.8000\n","7m 8s (- 0m 58s) (8800 88%) 0.7513\n","7m 13s (- 0m 53s) (8900 89%) 0.7096\n","7m 18s (- 0m 48s) (9000 90%) 0.7082\n","7m 23s (- 0m 43s) (9100 91%) 0.7636\n","7m 29s (- 0m 39s) (9200 92%) 0.7665\n","7m 35s (- 0m 34s) (9300 93%) 0.7916\n","7m 41s (- 0m 29s) (9400 94%) 0.7543\n","7m 46s (- 0m 24s) (9500 95%) 0.6984\n","7m 51s (- 0m 19s) (9600 96%) 0.6854\n","7m 56s (- 0m 14s) (9700 97%) 0.7542\n","8m 1s (- 0m 9s) (9800 98%) 0.7373\n","8m 6s (- 0m 4s) (9900 99%) 0.7100\n","8m 11s (- 0m 0s) (10000 100%) 0.7140\n"]}],"source":["train_iterations(encoder_exp_2, attn_decoder_exp_2, 10000, print_every=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"825c7142088549c5b524881463b8eb34","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":13478,"execution_start":1670505430680,"source_hash":"e13b4d80","tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":[]},{"data":{"text/plain":["0.0"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["evaluate(test_dataset, encoder_exp_2, attn_decoder_exp_2)"]},{"cell_type":"markdown","metadata":{"cell_id":"58d77281f8ff46aa8124835bd73212a9","deepnote_cell_type":"text-cell-h3","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["### Experiment 3"]},{"cell_type":"markdown","metadata":{"cell_id":"2db6686e0951479c9500c5a1d1fb7d89","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["The best performance is achieved by\n","a GRU network with attention, one layer with 100 hidden\n","units, and dropout of 0.1 (90.3% accuracy). "]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"2bfbc1a109ab460a81c8e56a56db610d","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":"b623e53d","tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown","tags":[]},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ec00d141-8917-4313-a10a-78395d2ec852' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"aa078de21384434e9243e98f7929ffe5","deepnote_persisted_session":{"createdAt":"2022-12-08T13:47:47.198Z"},"kernelspec":{"display_name":"Python 3.9.15 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"},"orig_nbformat":2,"vscode":{"interpreter":{"hash":"a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"}}},"nbformat":4,"nbformat_minor":0}
